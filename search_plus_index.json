{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction 记录数据工程师的必要技能学习，从各大招聘网站的要求扒来的 从hints @ Soreine下载的插件，支持四种模式 {% hint style='info'|'tip'|'danger'|'working' %} {% endhint %} 点击显示 {% reveal text=\"点击显示\" %} 要被隐藏的内容 {% endreveal %} 参考资料 算法工程面试 @ SpongeBob dennislblog            更新时间 2020-08-11 01:16:22 "},"deep/":{"url":"deep/","title":"Deep Learning","keywords":"","body":"Deep Learning dennislblog            更新时间 2020-08-10 21:41:37 "},"deep/ji-ben-zhi-shi.html":{"url":"deep/ji-ben-zhi-shi.html","title":"基本知识","keywords":"","body":"基本知识 模型评估方法 Accuracy作为指标有哪些局限性？ 不平衡分类问题 ROC和PR曲线是什么？ ROC是false positive rate-- true positive rate曲线，假设二元分类，每个样例对应一个$[0,1]$的概率，根据阈值的不同，输出一组TPR-FPR对应ROC上的一个点；PR不同于ROC的是对正负样本分布敏感 FPR=FP/N，TPR=TP/P，TP + FP = P' Precision = TP/P', Recall = TP/P $P'$代表所有预测$P$的数量 为什么AUC比precision要好 比如一个坏账率，$P$很少，假设一个分类器全部预测成$N$，准确率会很高 但如果用AUC描述，由于TP和FP都是$0$ ($P'=0$嘛)，而全部预测$P$，则TPR=FPR=1，因此这个分类器的ROC就是连接(0,0)和(1,1)，AUC=$0.5$ 如何计算AUC？ 由于AUC的定义就是从正负样本中随机抽取一个，正样本概率大于负样本 可以穷举所有正-负样本对（一个正样本与一个负样本），逐一比较他们的概率，如果正大于负，取1，小于取0，等于取0.5，然后相加除以假设全部是1。如果不能穷举则可以通过抽样估算 如何划分训练集？如何选取验证集？ 可以选择交叉验证，特别是数据量小或者不平衡分类问题时，比如我项目里用到的nested cross validation的方法来节省数据量 什么是偏差和方差？ 偏差是估计期望和真实期望的差距，而方差是估计的离散性，越大代表模型预测越不稳定 mean square error $MSE = \\mathbb{E}[(\\hat \\theta_m - \\theta)^2] = \\text{Bias}(\\hat \\theta_m)^2 + Var(\\hat \\theta_m)$ 所以过度追求训练集上的偏差小，容易导致测试集上偏差大（过拟合） 欠拟合和过拟合问题 深度学习解决过拟合的方法有哪些? 增加训练集，增加数据代表性 限制模型表达能力，比如 $l_1, l_2$ 正则化 dropout通过不断随机删除隐藏层神经元的办法，用集合学习的策略来抵消不同神经网络的过拟合（类似于cross validation validation）并且减少了神经元之间的联系和对某一些神经元的过度输出（更加robust，进化是增加适应性，而非依赖某一特定环境） 另一个减小过拟合的办法是batch normalization，为了解决所谓中间隐藏层数据分布一直随着前一层参数变化而变化的internal covariate shift问题，即对上一层输出先做一个预处理，通过对i层j个数据（1个batch）的normalization实现每一个神经元的输入分布都稳定但是仅仅这样做容易导致数据原本都是正的结果正则化成负的导致在激活层被丢弃，丧失了表达性，因此他引入了两个线性表达式参数将标准数转换到原来的范围？ 提前结束训练，防止过拟合 集合学习（原因见dropout） 解决欠拟合的方法有哪些？ 增加模型复杂度 调整模型初始化方式，在参数为$0$或者$1$的地方容易梯度消失，导致整个神经链失去传导能力 调整学习率，可能学习率太大了 集合学习 深度模型参数调整的一般方法？ 学习率：小->大->小 初始化参数 优化器的选择 损失函数的选择（cross entropy, l2 loss ...） 可视化 从小数据大模型入手，先过拟合，再增加数据并根据需要调整模型复杂度 深度学习基础 relu激活层，MSE作为损失函数推导反向传播 先通过前向传播把每个值算出来，再通过反向传播计算每一个神经元的梯度：比如最后一个神经元梯度是1.00, 倒数第二个是$\\partial \\frac{1}{x} |_{x=1.37}\\times 1.00 = -0.53$，记住加法分配，乘法加法，最大值继承等 相关见这个例子和这个 dropout如何实现反向传播的 假设每一个神经元以$p$的概率被丢弃，而没被丢弃的神经元信号放大$(1-p)^{-1}$倍，把这个函数定义为mask。 假设一个输入向量$x$，经$p$的dropout函数变换后得到向量$d$，在前向传播得到误差为$E$(标量)，则反向传播梯度为 \\nabla_x E = \\nabla_d E \\odot \\textbf{mask}(\\mathbf{x}) 常用的激活函数，导数？ sigmoid: $\\sigma(x) = (1+e^{-x})^{-1}$, $\\partial \\sigma(x) = \\sigma(x)(1-\\sigma(x))$，导数取值范围是$(0,0.25]$，很容易梯度消失 tanh: $\\tanh(x) = (e^x+e^{-x})^{-1}(e^x-e^{-x})$, $\\partial \\tanh(x) = 1-\\tanh^2(x)$，导数取值范围是$[0,1)$ Relu: $f(x) = x * \\mathbb{1}_{x\\geq 0}, \\partial f(x) = \\mathbb{1}_{x\\geq 0}$，导数取值要不$1$要不$0$，且在$x=0$不可导 leaky Relu: $g(x) = x \\text{ if } x \\geq \\lambda \\text{ else } \\lambda x$, $\\partial g(x) = 1 \\text{ if } x \\geq \\lambda \\text{ else } \\lambda$，为了解决Relu函数在$x 相关见这里 梯度消失与梯度膨胀，以及解决措施 根据链式法则，如果每一层神经元对上一层输出的偏导乘上权重结果都小于$1$，则经过多层传播后，误差对输入层的偏导会趋于$0$，这就是梯度消失，相反，如果每层都大于$1$，则误差对输入层的偏导趋于无穷大，这就是梯度爆炸 当梯度很大，会出现函数值跳来跳去的情况，一种解决办法是调整学习率，另一种办法叫做Gradient Clipping梯度裁剪，如果梯度的$l_2$范数$\\| g \\|_2 $大于阈值$c$，则把梯度缩小$\\frac{c}{\\| g \\|_2}$倍，另一种防止梯度过大的方法是在损失函数中加入regularization限制权值的范数 另外batchnorm也被用于解决梯度问题，正向传播中的$f_2 = f_1 (w^Tx + b)$在反向传播中$\\partial f_2 / \\partial w = (\\partial f_2 / \\partial f_1)\\cdot x$因此这一层的输入会影响梯度的消失和爆炸。batchnorm通过对每一层输出规范为均值和方差一致的办法，消除了下一层输入带来的放缩影响 何凯明大神提出的残差网络结构，用堆叠的神经网络去拟合一个residual mapping $F(x) = H(x) - x$ 这样如果残差网络梯度消失，至少identity mapping能保证无损地传播梯度 \\begin{align*} \\frac{\\partial \\text{loss}}{\\partial x_l} &= \\frac{\\partial \\text{loss}}{\\partial x_L}\\cdot \\frac{\\partial X_L}{\\partial x_l} \\cr &= \\frac{\\partial \\text{loss}}{\\partial x_L}\\cdot \\left(1 + \\frac{\\partial}{\\partial x_L}\\sum_{i=l}^{L-1}F(x_i, W_i)\\right) \\end{align*} 第一个因子$\\partial \\text{loss} / \\partial x_L$代表损失函数到达$L$的梯度，然后$l \\rightarrow L-1$都是residual net dennislblog            更新时间 2020-08-11 14:58:23 "},"deep/you-hua-fang-fa.html":{"url":"deep/you-hua-fang-fa.html","title":"优化方法","keywords":"","body":"优化方法 常用的优化器有哪些？ 一般框架，在每个epoch进行如下 计算目标函数关于当前参数的梯度：$g_t = \\nabla f(w_t)$ 根据历史梯度计算一阶动量和二阶动量：$m_t = \\phi(g_1, \\cdots, g_t), V_t = \\Phi(g_1, \\cdots, g_t)$ 计算当前时刻的下降梯度: $\\eta_t = \\alpha(V_t)^{-\\frac{1}{2}}m_t$ 根据下降梯度更新 $w_{t+1} = w_t - \\eta_t$ SGD: 没有考虑历史梯度 SGD with momentum: $m_t = \\beta m_{t-1} + (1-\\beta)g_t$ NAG：牛顿加速 $g_t = \\nabla f(w_t - \\eta_{t-1})$ 即假设已经更新到了那里 AdaGrad: 加入二阶动量$V_t = \\sum_{t}g_t^2$ 在梯度变化大的时候更新就小一些 AdaDelta：二阶动量 with momentum: $V_t = \\beta V_{t-1} + (1-\\beta) g_t^2$ Adam：把momentum的一阶和二阶全部考虑进来 NAdam：结合Adam和NAG别，考虑未来时刻，也考虑momentum 常用的损失函数有哪些？ 对于分类问题有：log loss: $\\log(1+\\exp(-f\\cdot y))$, focal loss, kl divergence entropy loss: $-\\log((1+f\\cdot y)/2)$, exponential loss 和 hinge loss: $\\max(0, 1-f\\cdot y)$ 对于回归问题有：mse: $(f-y)^2$, mean absolute error: $|f-y|$, huber loss在$|f-y|$小的地方用MSE，在$|f-y|>\\delta$的地方，用对异常值不那么敏感的$l_1$loss: $2\\delta|f-y|-\\delta^2$ 梯度下降法和牛顿法（拟牛顿法暂略） 批量梯度下降batch gradient descent使用所有样本，stochastic gradient descent随机选择一个样本求梯度，mini-batch gradient descent是前两者的折中，可以调整 牛顿法可以求方程的根，根据泰勒近似，f(x_{n+1}) = f(x_n) + f'(x_n)(x_{n+1} - x_n)因为我们希望找到一阶梯度为$0$的参数值：$w' = w - \\nabla_wf(w)(\\text{Hess}_w)^{-1}$ (当学习率为1，梯度下降的公式是$w' = w - \\nabla_wf(w)$) 牛顿法：不是朝梯度下降最快的方向更新，而是更进一步考虑到了梯度的变化，收敛也是局部的，并且要求可逆的二阶矩阵正定，否则可能朝梯度增大方向更新 什么是生成模型什么是判别模型？ 判别模型是在给出一个手写数字的部分图片信息下，判断这个数字是$0-9$的概率 生成模型则更关注联合概率而非条件概率，比如识别这个图和数字分别是$0-9$的联合概率，比如手里有大量这个人的手写数字的笔迹，通过一个生成器来模仿这些笔迹 生成模型：蓝色虚线代表判别器分类标准，黑色虚线代表真实样本分布情况，绿色实线代表生成样本的分布，$Z$代表随机噪音向量，是生成器的输入 $l_1$和$l_2$正则分别有什么特点？为何$l_1$稀疏？ p-norm: $\\| x\\|_p = \\left(\\sum_i^n |x_i|^p\\right)^{\\frac{1}{p}}$ $l_1$损失函数更稳定（异常值处理），但导数不连续，不好求最优解。所以huber损失函数完美结合了$l_1$和$l_2$，使得他既不对异常噪音敏感，也不是一成不变的梯度值，梯度会随着损失的减小而减小，从而不会错过最优点，唯一的问题就是他有一个超参数阈值$\\delta$ dennislblog            更新时间 2020-08-12 15:59:36 "},"deep/rnn.html":{"url":"deep/rnn.html","title":"循环神经网络","keywords":"","body":"循环神经网络 dennislblog            更新时间 2020-08-10 21:41:37 "},"algorithm/":{"url":"algorithm/","title":"Algorithm","keywords":"","body":"Algorithm dennislblog            更新时间 2020-08-10 21:41:37 "},"algorithm/er-cha-shu-lei.html":{"url":"algorithm/er-cha-shu-lei.html","title":"二叉树类","keywords":"","body":"二叉树类 dennislblog            更新时间 2020-08-10 21:41:37 "},"algorithm/sou-suo-hui-su.html":{"url":"algorithm/sou-suo-hui-su.html","title":"搜索回溯","keywords":"","body":"搜索回溯 dennislblog            更新时间 2020-08-10 21:41:37 "},"algorithm/shu-xue-ti.html":{"url":"algorithm/shu-xue-ti.html","title":"数学题","keywords":"","body":"数学题 dennislblog            更新时间 2020-08-10 21:41:37 "},"algorithm/dong-tai-gui-hua.html":{"url":"algorithm/dong-tai-gui-hua.html","title":"动态规划","keywords":"","body":"动态规划 dennislblog            更新时间 2020-08-10 21:41:37 "},"algorithm/zheng-ze-biao-da.html":{"url":"algorithm/zheng-ze-biao-da.html","title":"正则表达","keywords":"","body":"正则表达 dennislblog            更新时间 2020-08-10 21:41:37 "},"database/":{"url":"database/","title":"Database","keywords":"","body":"Database 特别鸣谢 MySQL数据库面试题 @ThinkWon dennislblog            更新时间 2020-08-12 16:02:51 "},"database/ji-ben-zhi-shi.html":{"url":"database/ji-ben-zhi-shi.html","title":"基本知识","keywords":"","body":"基本知识 数据库三大范式 第一范式：要求属性具有原子性，不可以再被拆分 如表(学号，姓名，性别，出生年月日)，如果认为最后一列还可以再分成(年，月，日)，就违反第一范式 第二范式：非主键列的数据提取完全依赖于主键，不存在部分依赖，记录具有唯一标识性(这个主键可以由多个列决定) 如表(学号，课程号，姓名，学分)，学分依赖课程号，姓名依赖学号，那些没选课的学生有两列都是NULL，违反第二范式 正确做法是设计三个表，第一个表学生(学号，姓名)，第二个表课程(课程号，学分)，第三个表选课关系(学号，课程号，成绩) 第三范式：数据尽量不要啰嗦 如表(学号，姓名，年龄，学院名称，学院电话)，很多学生在同一个学院，这样学院和电话这两栏就会有大量信息冗余 正确做法是设计两个表，一个学生(学号，姓名，年龄，所在学院)，一个学院(学院，电话) dennislblog            更新时间 2020-08-12 23:29:31 "},"database/wei-gui-lei.html":{"url":"database/wei-gui-lei.html","title":"未归类","keywords":"","body":"未归类 先创建一个数据表 --假设你已经连接到相应的数据库里 create table temp_table(id int primary key, grade decimal(4,2)); --输入(id, grade)数据 insert into temp_table values (1,78), (2,80.5), (3,95), (4,47), (5,66), (6,null); --插入新的一列`time`，设置为当前时间（用now()函数, set one value to all） alter table temp_table add column timenow datetime; update temp_table set timenow=now(); --删除column操作: alter table temp_table drop column timenow; --描述table操作: describe temp_table; --创造一个临时的table存储要插入的变量 create temporary table tmp (id int, user_name varchar(30)); insert into tmp values (1, \"12bc\"),(2, \"abcd\"),(3, \"3456\"),(4, \"56cd\"),(5, \"00gg\"),(6, \"ggbc\"); --插入新的一列`user_name` alter table temp_table add user_name varchar(30) default NULL after id; --选取临时表tmp中的user_name插入到temp_table里(匹配id) update temp_table as a, tmp as b set a.user_name = b.user_name where a.id = b.id; 结果如下 +----+-----------+-------+---------------------+ | id | user_name | grade | timenow | +----+-----------+-------+---------------------+ | 1 | 12bc | 78.00 | 2020-08-12 22:08:26 | | 2 | abcd | 80.50 | 2020-08-12 22:08:26 | | 3 | 3456 | 95.00 | 2020-08-12 22:08:26 | | 4 | 56cd | 47.00 | 2020-08-12 22:08:26 | | 5 | 00gg | 66.00 | 2020-08-12 22:08:26 | | 6 | ggbc | NULL | 2020-08-12 22:08:26 | +----+-----------+-------+---------------------+ 条件判断 情境：根据上面学生的成绩，给出优，中，差三个评级 ```sql -- 1) 用if实现 select user_name, grade, if(grade>=60, if(grade>80, 'good', 'not bad'), 'bad') as grade_judge from temp_table; -- 2) 用case when实现 select user_name, grade, case when grade > 80 then 'good' when grade between 60 and 80 then 'not bad' else 'bad' end as grade_judge from temp_table; 结果如下 +-----------+-------+-------------+ | user_name | grade | grade_judge | +-----------+-------+-------------+ | 12bc | 78.00 | not bad | | abcd | 80.50 | good | | 3456 | 95.00 | good | | 56cd | 47.00 | bad | | 00gg | 66.00 | not bad | | ggbc | NULL | bad | +-----------+-------+-------------+ > where运算符(如果条件是主键，理论上应该会快一些) >> 逻辑符号涉及 `=`, `!=`, `>=`, `like模糊查找: % 表示全部匹配，_ 下划线表示匹配一个字符；例如look%代表匹配look开头的信息 情境：在上面的表中，提取user_name里全部为数字或全部为字母的同学的成绩记录(貌似不识别regex)，改成提取user_name末尾字母为d的信息 select * from temp_table where user_name like \"%d\"; 结果如下 +----+-----------+-------+---------------------+ | id | user_name | grade | timenow | +----+-----------+-------+---------------------+ | 2 | abcd | 80.50 | 2020-08-12 22:08:26 | | 4 | 56cd | 47.00 | 2020-08-12 22:08:26 | +----+-----------+-------+---------------------+ dennislblog            更新时间 2020-08-13 00:30:11 "},"database/guan-lian-cha-xun.html":{"url":"database/guan-lian-cha-xun.html","title":"关联查询","keywords":"","body":"关联查询 创建一个数据表例子 # sqlsh \\connect --mysql xiang@localhost use test; create table NAME (`id` int, `name` char(40)); create table AGE (`id` int, `age` int); insert into NAME (id, name) values (1,\"Joe\"), (2,\"Henry\"), (3,\"Sam\"), (4,\"Max\"), (8,\"Jack\"); insert into AGE (id, age) values (1,28), (2,18), (3,21), (4,32), (5,35); 结果如下 # NAME # AGE +----+-------+ +----+-------+ | id | name | | id | age | +----+-------+ +----+-------+ | 1 | Joe | | 1 | 28 | | 2 | Henry | | 2 | 18 | | 3 | Sam | | 3 | 21 | | 4 | Max | | 4 | 32 | | 8 | Jack | | 5 | 35 | +----+-------+ +----+-------+ inner join内连接也称为等值连接，只返回两个表关键字都匹配的部分 select * from NAME inner join AGE on NAME.id = AGE.id; --OR select * from NAME, AGE where NAME.id=AGE.id; 结果如下 +----+-------+----+-----+ | id | name | id | age | +----+-------+----+-----+ | 1 | Joe | 1 | 28 | | 2 | Henry | 2 | 18 | | 3 | Sam | 3 | 21 | | 4 | Max | 4 | 32 | +----+-------+----+-----+ left join左连接，必须返回左表的全部内容，然后匹配加入右表内容 select * from NAME left join AGE on NAME.id = AGE.id; 结果如下 +----+-------+------+------+ | id | name | id | age | +----+-------+------+------+ | 1 | Joe | 1 | 28 | | 2 | Henry | 2 | 18 | | 3 | Sam | 3 | 21 | | 4 | Max | 4 | 32 | | 8 | Jack | NULL | NULL | +----+-------+------+------+ right join右连接，必须返回右表的全部内容，然后匹配加入左表内容 左连接和右连接都是外连接的一种方式 select * from NAME right join AGE on NAME.id = AGE.id; 结果如下 +------+-------+----+-----+ | id | name | id | age | +------+-------+----+-----+ | 1 | Joe | 1 | 28 | | 2 | Henry | 2 | 18 | | 3 | Sam | 3 | 21 | | 4 | Max | 4 | 32 | | NULL | NULL | 5 | 35 | +------+-------+----+-----+ cross join返回两张表的笛卡尔乘积，检查交互作用 select * from NAME cross join AGE; 结果如下 +----+-------+----+-----+ | id | name | id | age | +----+-------+----+-----+ | 1 | Joe | 1 | 28 | | 2 | Henry | 1 | 28 | | 3 | Sam | 1 | 28 | | 4 | Max | 1 | 28 | | 8 | Jack | 1 | 28 | | 1 | Joe | 2 | 18 | | 2 | Henry | 2 | 18 | | 3 | Sam | 2 | 18 | | 4 | Max | 2 | 18 | | 8 | Jack | 2 | 18 | | 1 | Joe | 3 | 21 | | 2 | Henry | 3 | 21 | | 3 | Sam | 3 | 21 | | 4 | Max | 3 | 21 | | 8 | Jack | 3 | 21 | | 1 | Joe | 4 | 32 | | 2 | Henry | 4 | 32 | | 3 | Sam | 4 | 32 | | 4 | Max | 4 | 32 | | 8 | Jack | 4 | 32 | | 1 | Joe | 5 | 35 | | 2 | Henry | 5 | 35 | | 3 | Sam | 5 | 35 | | 4 | Max | 5 | 35 | | 8 | Jack | 5 | 35 | +----+-------+----+-----+ union | union all联合查询，把选取的内容做一个合集(union all重复放入集合) select id from NAME union select id from AGE; 结果如下 +----+ | id | +----+ | 1 | | 2 | | 3 | | 4 | | 8 | | 5 | +----+ dennislblog            更新时间 2020-08-12 17:40:43 "},"database/shu-ju-ku-you-hua.html":{"url":"database/shu-ju-ku-you-hua.html","title":"数据库优化","keywords":"","body":"数据库优化 dennislblog            更新时间 2020-08-12 03:50:17 "}}